# Unit Tests for Work Feature

## Test 1: Init-test
Objective: Verify basic maestro initialization and track/phase/task creation

Steps:
1. Run `maestro init` to initialize the project
2. Add tracks, phases and tasks to create a simple CLI program for scientific calculation
3. Verify that the commands work correctly
4. Check that track/phase/task lists display the created items

Expected Success Criteria:
- All commands execute without errors
- Track/phase/task lists show the items that were created

## Test 2: Work-test
Objective: Verify the work feature with breadcrumbs and AI synchronization

Steps:
1. Run `maestro init` to initialize the project
2. Create a track, phase and task
3. Define 5 points for the task (foobar points - be creative):
   - Point A: Implement basic calculation function
   - Point B: Add input validation
   - Point C: Create output formatting
   - Point D: Add error handling
   - Point E: Optimize performance
4. After each point, verify breadcrumbs are created (as implemented in phase ws2)
5. After the 5th point, use AI to respond as JSON using `python maestro.py ai` command
6. Execute `maestro work task <task-id>` to start working on the task
7. Use the appropriate command to display all breadcrumbs, responses, and AI synchronizations

Expected Success Criteria:
- Breadcrumbs are properly recorded between each point
- AI responds with JSON after the 5th point
- The command to display breadcrumbs shows all recorded breadcrumbs and responses
- AI synchronization works as expected